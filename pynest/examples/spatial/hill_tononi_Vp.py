# -*- coding: utf-8 -*-
#
# hill_tononi_Vp.py
#
# This file is part of NEST.
#
# Copyright (C) 2004 The NEST Initiative
#
# NEST is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# NEST is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with NEST.  If not, see <http://www.gnu.org/licenses/>.

# ! ===========================================
# ! NEST Topology Module: A Case-Based Tutorial
# ! ===========================================
# !
# ! :Author: Hans Ekkehard Plesser
# ! :Institution: Norwegian University of Life Sciences
# ! :Version: 0.4
# ! :Date: 21 November 2012
# ! :Copyright: The NEST Initiative (2004)
# ! :License: Creative Commons Attribution License
# !
# ! **NOTE:** The network generated by this script does generate
# ! dynamics in which the activity of the entire system, especially
# ! Rp and Vp oscillates with approx 5 Hz. This is different from
# ! the full model. Deviations are due to the different model type
# ! and the elimination of a number of connections, with no changes
# ! to the weights.
# !
# ! Introduction
# ! ============
# !
# ! This tutorial shows you how to implement a simplified version of the
# ! Hill-Tononi model of the early visual pathway using the NEST Topology
# ! module.  The model is described in the paper
# !
# !   S. L. Hill and G. Tononi.
# !   Modeling Sleep and Wakefulness in the Thalamocortical System.
# !   J Neurophysiology **93**:1671-1698 (2005).
# !   Freely available via `doi 10.1152/jn.00915.2004
# !   <http://dx.doi.org/10.1152/jn.00915.2004>`_.
# !
# ! We simplify the model somewhat both to keep this tutorial a bit
# ! shorter, and because some details of the Hill-Tononi model are not
# ! currently supported by NEST. Simplifications include:
# !
# ! 1. We use the ``iaf_cond_alpha`` neuron model, which is
# !    simpler than the Hill-Tononi model.
# !
# ! #. As the ``iaf_cond_alpha`` neuron model only supports two
# !    synapses (labeled "ex" and "in"), we only include AMPA and
# !    GABA_A synapses.
# !
# ! #. We ignore the secondary pathway (Ts, Rs, Vs), since it adds just
# !    more of the same from a technical point of view.
# !
# ! #. Synaptic delays follow a Gaussian distribution in the HT
# !    model. This implies actually a Gaussian distributions clipped at
# !    some small, non-zero delay, since delays must be
# !    positive. Currently, there is a bug in the Topology module when
# !    using clipped Gaussian distribution. We therefore draw delays from a
# !    uniform distribution.
# !
# ! #. Some further adaptations are given at the appropriate locations in
# !    the script.
# !
# ! This tutorial is divided in the following sections:
# !
# ! Philosophy_
# !    Discusses the philosophy applied to model implementation in this
# !    tutorial
# !
# ! Preparations_
# !    Neccessary steps to use NEST and the Topology Module
# !
# ! `Configurable Parameters`_
# !    Define adjustable network parameters
# !
# ! `Neuron Models`_
# !    Define the neuron models needed by the network model
# !
# ! Populations_
# !    Create Populations
# !
# ! `Synapse models`_
# !    Define the synapse models used in the network model
# !
# ! Connections_
# !    Create Connections
# !
# ! `Example simulation`_
# !    Perform a small simulation for illustration. This
# !    section also discusses the setup for recording.

# ! Philosophy
# ! ==========

# ! A network models has two essential components: *populations* and
# ! *projections*.  We first use NEST's ``CopyModel()`` mechanism to
# ! create specific models for all populations and subpopulations in
# ! the network, and then create the populations using the
# ! ``Create()`` function.
# !
# ! We use a two-stage process to create the connections, mainly
# ! because the same configurations are required for a number of
# ! projections: we first define dictionaries specifying the
# ! connections, then apply these dictionaries later.
# !
# ! The way in which we declare the network model here is an
# ! example. You should not consider it the last word: we expect to see
# ! a significant development in strategies and tools for network
# ! descriptions in the future. The following contributions to CNS\*09
# ! seem particularly interesting
# !
# ! - Ralf Ansorg & Lars Schwabe. Declarative model description and
# !   code generation for hybrid individual- and population-based
# !   simulations of the early visual system (P57);
# ! - Sharon Crook, R. Angus Silver, & Padraig Gleeson. Describing
# !   and exchanging models of neurons and neuronal networks with
# !   NeuroML (F1);
# !
# ! as well as the following paper which will apply in PLoS
# ! Computational Biology shortly:
# !
# ! - Eilen Nordlie, Marc-Oliver Gewaltig, & Hans Ekkehard Plesser.
# !   Towards reproducible descriptions of neuronal network models.

# ! Preparations
# ! ============

# ! Please make sure that your ``PYTHONPATH`` is set correctly, so
# ! that Python can find the NEST Python module.

# ! **Note:** By default, the script does not show any graphics.
# ! Set ``SHOW_FIGURES`` to ``True`` to activate graphics.

from pprint import pprint
import numpy as np
import matplotlib.pyplot as plt

SHOW_FIGURES = False

if SHOW_FIGURES:
    plt.ion()
else:
    plt_show = plt.show

    def nop(s=None, block=None):
        pass

    plt.show = nop

# ! Introduction
# !=============
# ! This tutorial gives a brief introduction to the ConnPlotter
# ! toolbox. It is by no means complete.

# ! Load pynest
import nest

# ! Make sure we start with a clean slate, even if we re-run the script
# ! in the same Python session.
nest.ResetKernel()

# ! Import math, we need Pi
import math

# ! Configurable Parameters
# ! =======================
# !
# ! Here we define those parameters that we take to be
# ! configurable. The choice of configurable parameters is obviously
# ! arbitrary, and in practice one would have far more configurable
# ! parameters. We restrict ourselves to:
# !
# ! - Network size in neurons ``N``, each layer is ``N x N``.
# ! - Network size in subtended visual angle ``visSize``, in degree.
# ! - Temporal frequency of drifting grating input ``f_dg``, in Hz.
# ! - Spatial wavelength and direction of drifting grating input,
# !   ``lambda_dg`` and ``phi_dg``, in degree/radian.
# ! - Background firing rate of retinal nodes and modulation amplitude,
# !   ``retDC`` and ``retAC``, in Hz.
# ! - Simulation duration ``simtime``; actual simulation is split into
# !   intervals of ``sim_interval`` length, so that the network state
# !   can be visualized in those intervals. Times are in ms.
# ! - Periodic boundary conditions, ``edge_wrap``.
Params = {'N': 40,
          'visSize': 8.0,
          'f_dg': 2.0,
          'lambda_dg': 2.0,
          'phi_dg': 0.0,
          'retDC': 30.0,
          'retAC': 30.0,
          'simtime': 100.0,
          'sim_interval': 1.0,
          'edge_wrap': True
          }

# ! Neuron Models
# ! =============
# !
# ! We declare models in two steps:
# !
# ! 1. We define a dictionary specifying the NEST neuron model to use
# !    as well as the parameters for that model.
# ! #. We create three copies of this dictionary with parameters
# !    adjusted to the three model variants specified in Table~2 of
# !    Hill & Tononi (2005) (cortical excitatory, cortical inhibitory,
# !    thalamic)
# !
# ! In addition, we declare the models for the stimulation and
# ! recording devices.
# !
# ! The general neuron model
# ! ------------------------
# !
# ! We use the ``iaf_cond_alpha`` neuron, which is an
# ! integrate-and-fire neuron with two conductance-based synapses which
# ! have alpha-function time course.  Any input with positive weights
# ! will automatically directed to the synapse labeled ``_ex``, any
# ! with negative weights to the synapes labeled ``_in``.  We define
# ! **all** parameters explicitly here, so that no information is
# ! hidden in the model definition in NEST. ``V_m`` is the membrane
# ! potential to which the model neurons will be initialized.
# ! The model equations and parameters for the Hill-Tononi neuron model
# ! are given on pp. 1677f and Tables 2 and 3 in that paper. Note some
# ! peculiarities and adjustments:
# !
# ! - Hill & Tononi specify their model in terms of the membrane time
# !   constant, while the ``iaf_cond_alpha`` model is based on the
# !   membrane capcitance. Interestingly, conducantces are unitless in
# !   the H&T model. We thus can use the time constant directly as
# !   membrane capacitance.
# ! - The model includes sodium and potassium leak conductances. We
# !   combine these into a single one as follows:
# $   \begin{equation}-g_{NaL}(V-E_{Na}) - g_{KL}(V-E_K)
# $      = -(g_{NaL}+g_{KL})
# $        \left(V-\frac{g_{NaL}E_{NaL}+g_{KL}E_K}{g_{NaL}g_{KL}}\right)
# $   \end{equation}
# ! - We write the resulting expressions for g_L and E_L explicitly
# !   below, to avoid errors in copying from our pocket calculator.
# ! - The paper gives a range of 1.0-1.85 for g_{KL}, we choose 1.5
# !   here.
# ! - The Hill-Tononi model has no explicit reset or refractory
# !   time. We arbitrarily set V_reset and t_ref.
# ! - The paper uses double exponential time courses for the synaptic
# !   conductances, with separate time constants for the rising and
# !   fallings flanks. Alpha functions have only a single time
# !   constant: we use twice the rising time constant given by Hill and
# !   Tononi.
# ! - In the general model below, we use the values for the cortical
# !   excitatory cells as defaults. Values will then be adapted below.
# !
nest.CopyModel('iaf_cond_alpha', 'NeuronModel',
               params={'C_m': 16.0,
                       'E_L': (0.2 * 30.0 + 1.5 * -90.0) / (0.2 + 1.5),
                       'g_L': 0.2 + 1.5,
                       'E_ex': 0.0,
                       'E_in': -70.0,
                       'V_reset': -60.0,
                       'V_th': -51.0,
                       't_ref': 2.0,
                       'tau_syn_ex': 1.0,
                       'tau_syn_in': 2.0,
                       'I_e': 0.0,
                       'V_m': -70.0})

# ! Adaptation of models for different populations
# ! ----------------------------------------------

# ! We must copy the `NeuronModel` dictionary explicitly, otherwise
# ! Python would just create a reference.

# ! Cortical excitatory cells
# ! .........................
# ! Parameters are the same as above, so we need not adapt anything
nest.CopyModel('NeuronModel', 'CtxExNeuron')

# ! Cortical inhibitory cells
# ! .........................
nest.CopyModel('NeuronModel', 'CtxInNeuron',
               params={'C_m': 8.0,
                       'V_th': -53.0,
                       't_ref': 1.0})

# ! Thalamic cells
# ! ..............
nest.CopyModel('NeuronModel', 'ThalamicNeuron',
               params={'C_m': 8.0,
                       'V_th': -53.0,
                       't_ref': 1.0,
                       'E_in': -80.0})


# ! Input generating nodes
# ! ----------------------

# ! Input is generated by sinusoidally modulate Poisson generators,
# ! organized in a square layer of retina nodes. These nodes require a
# ! slightly more complicated initialization than all other elements of
# ! the network:
# !
# ! - Average firing rate ``rate``, firing rate modulation depth ``amplitude``,
# !   and temporal modulation frequency ``frequency`` are the same for all
# !   retinal nodes and are set directly below.
# ! - The temporal phase ``phase`` of each node depends on its position in
# !   the grating and can only be assigned after the retinal layer has
# !   been created.
nest.CopyModel('sinusoidal_poisson_generator', 'RetinaNode',
               params={'amplitude': Params['retAC'],
                       'rate': Params['retDC'],
                       'frequency': Params['f_dg'],
                       'phase': 0.0,
                       'individual_spike_trains': False})

# ! Recording nodes
# ! ---------------

# ! We use the ``multimeter`` device for recording from the model
# ! neurons. At present, ``iaf_cond_alpha`` is one of few models
# ! supporting ``multimeter`` recording.  Support for more models will
# ! be added soon; until then, you need to use ``voltmeter`` to record
# ! from other models.
# !
# ! We configure multimeter to record membrane potential to membrane
# ! potential at certain intervals to memory only. We record the GID of
# ! the recorded neurons, but not the time.
nest.CopyModel('multimeter', 'RecordingNode',
               params={'interval': Params['sim_interval'],
                       'record_from': ['V_m'],
                       'record_to': 'memory'})

# ! Populations
# ! ===========

# ! We now create the neuron populations in the model. We define
# ! them in order from eye via thalamus to cortex.
# !
# ! We first define a spatial grid defining common positions and
# ! parameters for all populations
layerGrid = nest.spatial.grid(shape=[Params['N'], Params['N']],
                              extent=[Params['visSize'], Params['visSize']],
                              edge_wrap=Params['edge_wrap'])
# ! We can pass this object to the ``positions`` argument in ``Create``
# ! to define the positions of the neurons.

# ! Retina
# ! ------
retina = nest.Create('RetinaNode', positions=layerGrid)

# ! Now set phases of retinal oscillators; we create a Parameter
# ! which represents the phase based on the spatial properties of
# ! the neuron.

retina_phase = 360.0 / Params['lambda_dg'] * (math.cos(Params['phi_dg']) * nest.spatial.pos.x +
                                              math.sin(Params['phi_dg']) * nest.spatial.pos.y)
retina.set(phase=retina_phase)

# ! Thalamus
# ! --------

# ! We first introduce specific neuron models for the thalamic relay
# ! cells and interneurons. These have identical properties, but by
# ! treating them as different populations, we can address them specifically
# ! when building connections.
for model_name in ('TpRelay', 'TpInter'):
    nest.CopyModel('ThalamicNeuron', model_name)

# ! Now we can create the layers, one with relay cells,
# ! and one with interneurons:
TpRelay = nest.Create('TpRelay', positions=layerGrid)
TpInter = nest.Create('TpInter', positions=layerGrid)

# ! Reticular nucleus
# ! -----------------
nest.CopyModel('ThalamicNeuron', 'RpNeuron')
Rp = nest.Create('RpNeuron', positions=layerGrid)

# ! Primary visual cortex
# ! ---------------------

# ! We follow again the same approach as with Thalamus. We differentiate
# ! neuron types between layers and between pyramidal cells and
# ! interneurons. We have two layers for pyramidal cells, and two layers for
# ! interneurons for each of layers 2-3, 4, and 5-6. Finally, we need to
# ! differentiate between vertically and horizontally tuned populations.
# ! When creating the populations, we create the vertically and the
# ! horizontally tuned populations as separate dictionaries holding the
# ! layers.
for layer in ('L23', 'L4', 'L56'):
    nest.CopyModel('CtxExNeuron', layer + 'pyr')
for layer in ('L23', 'L4', 'L56'):
    nest.CopyModel('CtxInNeuron', layer + 'in')

name_dict = {'L23pyr': 2, 'L23in': 1,
             'L4pyr': 2, 'L4in': 1,
             'L56pyr': 2, 'L56in': 1}

# ! Now we can create the populations, suffixes h and v indicate tuning
Vp_h_layers = {}
Vp_v_layers = {}
for layer_name, num_layers in name_dict.items():
    for i in range(num_layers):
        Vp_h_layers['{}_{}'.format(layer_name, i)] = nest.Create(layer_name, positions=layerGrid)
        Vp_v_layers['{}_{}'.format(layer_name, i)] = nest.Create(layer_name, positions=layerGrid)

# ! Collect all populations
# ! -----------------------

# ! For reference purposes, e.g., printing, we collect all populations
# ! in a tuple:
populations = (retina, TpRelay, TpInter, Rp) + tuple(Vp_h_layers.values()) + tuple(Vp_v_layers.values())

# ! Inspection
# ! ----------

# ! We can now look at the network using `PrintNodes`:
nest.PrintNodes()

# ! We can also try to plot a single layer in a network. All layers have
# ! equal positions of the nodes.
nest.PlotLayer(Rp)
plt.title('Layer Rp')

# ! Synapse models
# ! ==============

# ! Actual synapse dynamics, e.g., properties such as the synaptic time
# ! course, time constants, reversal potentials, are properties of
# ! neuron models in NEST and we set them in section `Neuron models`_
# ! above. When we refer to *synapse models* in NEST, we actually mean
# ! connectors which store information about connection weights and
# ! delays, as well as port numbers at the target neuron (``rport``)
# ! and implement synaptic plasticity. The latter two aspects are not
# ! relevant here.
# !
# ! We just use NEST's ``static_synapse`` connector but copy it to
# ! synapse models ``AMPA`` and ``GABA_A`` for the sake of
# ! explicitness. Weights and delays are set as needed in section
# ! `Connections`_ below, as they are different from projection to
# ! projection. De facto, the sign of the synaptic weight decides
# ! whether input via a connection is handle by the ``_ex`` or the
# ! ``_in`` synapse.
nest.CopyModel('static_synapse', 'AMPA')
nest.CopyModel('static_synapse', 'GABA_A')

# ! Connections
# ! ====================

# ! Building connections is the most complex part of network
# ! construction. Connections are specified in Table 1 in the
# ! Hill-Tononi paper. As pointed out above, we only consider AMPA and
# ! GABA_A synapses here.  Adding other synapses is tedious work, but
# ! should pose no new principal challenges. We also use a uniform in
# ! stead of a Gaussian distribution for the weights.
# !
# ! The model has two identical primary visual cortex populations,
# ! ``Vp_v`` and ``Vp_h``, tuned to vertical and horizonal gratings,
# ! respectively. The *only* difference in the connection patterns
# ! between the two populations is the thalamocortical input to layers
# ! L4 and L5-6 is from a population of 8x2 and 2x8 grid locations,
# ! respectively. Furthermore, inhibitory connection in cortex go to
# ! the opposing orientation population as to the own.
# !
# ! To save us a lot of code doubling, we thus defined properties
# ! dictionaries for all connections first and then use this to connect
# ! both populations. We follow the subdivision of connections as in
# ! the Hill & Tononi paper.
# !
# TODO: Rewrite this note.
# ! **Note:** Hill & Tononi state that their model spans 8 degrees of
# ! visual angle and stimuli are specified according to this. On the
# ! other hand, all connection patterns are defined in terms of cell
# ! grid positions. Since the NEST Topology Module defines connection
# ! patterns in terms of the extent given in degrees, we need to apply
# ! the following scaling factor to all lengths in connections:
dpc = Params['visSize'] / (Params['N'] - 1)

# ! We will collect all same-orientation cortico-cortical connections in
ccConnections = []
# ! the cross-orientation cortico-cortical connections in
ccxConnections = []
# ! and all cortico-thalamic connections in
ctConnections = []

# ! Horizontal intralaminar
# ! -----------------------
# ! *Note:* "Horizontal" means "within the same cortical layer" in this
# ! case.
# !
# ! We first define dictionaries with the (most) common properties for
# ! horizontal intralaminar connection. We then create copies in which
# ! we adapt those values that need adapting, and
horIntra_conn_spec = {"rule": "pairwise_bernoulli",
                      "mask": {"circular": {"radius": 12.0 * dpc}},
                      "p": 0.05*nest.spatial_distributions.gaussian(nest.spatial.distance, std=7.5 * dpc)}

horIntra_syn_spec = {"synapse_model": "AMPA",
                     "weight": 1.0,
                     "delay": nest.random.uniform(min=1.75, max=2.25)}

# ! In a loop, we run over the sources and targets and the corresponding
# ! dictionaries with values that needs updating.
for conn in [{"sources": "L23pyr", "targets": "L23pyr", "conn_spec": {}},
             {"sources": "L23pyr", "targets": "L23in", "conn_spec": {}},
             {"sources": "L4pyr", "targets": "L4pyr", "conn_spec": {"mask": {"circular": {"radius": 7.0 * dpc}}}},
             {"sources": "L4pyr", "targets": "L4in", "conn_spec": {"mask": {"circular": {"radius": 7.0 * dpc}}}},
             {"sources": "L56pyr", "targets": "L56pyr", "conn_spec": {}},
             {"sources": "L56pyr", "targets": "L56in", "conn_spec": {}}]:
    conn_spec = horIntra_conn_spec.copy()
    conn_spec.update(conn['conn_spec'])
    ccConnections.append([conn['sources'], conn['targets'], conn_spec, horIntra_syn_spec])

# ! Vertical intralaminar
# ! -----------------------
# ! *Note:* "Vertical" means "between cortical layers" in this
# ! case.
# !
# ! We proceed as above.
verIntra_conn_spec = {"rule": "pairwise_bernoulli",
                      "mask": {"circular": {"radius": 2.0 * dpc}},
                      "p": nest.spatial_distributions.gaussian(nest.spatial.distance, std=7.5 * dpc)}

verIntra_syn_spec = {"synapse_model": "AMPA",
                     "weight": 2.0,
                     "delay": nest.random.uniform(min=1.75, max=2.25)}

for conn in [{"sources": "L23pyr", "targets": "L56pyr",
              "syn_spec": {"weight": 1.0}},
             {"sources": "L23pyr", "targets": "L23in",
              "syn_spec": {"weight": 1.0}},
             {"sources": "L4pyr", "targets": "L23pyr", "syn_spec": {}},
             {"sources": "L4pyr", "targets": "L23in", "syn_spec": {}},
             {"sources": "L56pyr", "targets": "L23pyr", "syn_spec": {}},
             {"sources": "L56pyr", "targets": "L23in", "syn_spec": {}},
             {"sources": "L56pyr", "targets": "L4pyr", "syn_spec": {}},
             {"sources": "L56pyr", "targets": "L4in", "syn_spec": {}}]:
    syn_spec = verIntra_syn_spec.copy()
    syn_spec.update(conn['syn_spec'])
    ccConnections.append([conn['sources'], conn['targets'], verIntra_conn_spec, syn_spec])

# ! Intracortical inhibitory
# ! ------------------------
# !
# ! We proceed as above, with the following difference: each connection
# ! is added to both the same-orientation and the cross-orientation list of
# ! connections.
# !
# ! **Note:** Weights increased from -1.0 to -2.0, to make up for missing GabaB
# !
# ! Note that we have to specify the **weight with negative sign** to make
# ! the connections inhibitory.
intraInh_conn_spec = {"rule": "pairwise_bernoulli",
                      "mask": {"circular": {"radius": 7.0 * dpc}},
                      "p": 0.25*nest.spatial_distributions.gaussian(nest.spatial.distance, std=7.5 * dpc)}

intraInh_syn_spec = {"synapse_model": "GABA_A",
                     "weight": -2.0,
                     "delay": nest.random.uniform(min=1.75, max=2.25)}

for conn in [{"sources": "L23in", "targets": "L23pyr", "conn_spec": {}},
             {"sources": "L23in", "targets": "L23in", "conn_spec": {}},
             {"sources": "L4in", "targets": "L4pyr", "conn_spec": {}},
             {"sources": "L4in", "targets": "L4in", "conn_spec": {}},
             {"sources": "L56in", "targets": "L56pyr", "conn_spec": {}},
             {"sources": "L56in", "targets": "L56in", "conn_spec": {}}]:
    conn_spec = intraInh_conn_spec.copy()
    conn_spec.update(conn['conn_spec'])
    ccConnections.append([conn['sources'], conn['targets'], conn_spec, intraInh_syn_spec])
    ccxConnections.append([conn['sources'], conn['targets'], conn_spec, intraInh_syn_spec])

# ! Corticothalamic
# ! ---------------
# ! We proceed as above.
corThal_conn_spec = {"rule": "pairwise_bernoulli",
                     "mask": {"circular": {"radius": 5.0 * dpc}},
                     "p": 0.5*nest.spatial_distributions.gaussian(nest.spatial.distance, std=7.5 * dpc)}

corThal_syn_spec = {"synapse_model": "AMPA",
                    "weight": 1.0,
                    "delay": nest.random.uniform(min=7.5, max=8.5)}

for conn in [{"sources":  "L56pyr", "conn_spec": {}}]:
    conn_spec = intraInh_conn_spec.copy()
    conn_spec.update(conn['conn_spec'])
    syn_spec = intraInh_syn_spec.copy()
    ctConnections.append([conn['sources'], conn_spec, syn_spec])

# ! Corticoreticular
# ! ----------------

# ! In this case, there is only a single connection, so we define the
# ! dictionaries directly; it is very similar to corThal, and to show that,
# ! we copy first, then update.
corRet = corThal_conn_spec.copy()
corRet_syn_spec = corThal_syn_spec.copy()
corRet_syn_spec.update({"weight": 2.5})

# ! Build all connections beginning in cortex
# ! -----------------------------------------

# ! Cortico-cortical, same orientation
print("Connecting: cortico-cortical, same orientation")
for source, target, conn_spec, syn_spec in ccConnections:
    for src_i in range(name_dict[source]):
        for tgt_i in range(name_dict[target]):
            source_name = '{}_{}'.format(source, src_i)
            target_name = '{}_{}'.format(target, tgt_i)
            nest.Connect(Vp_h_layers[source_name], Vp_h_layers[target_name], conn_spec, syn_spec)
            nest.Connect(Vp_v_layers[source_name], Vp_v_layers[target_name], conn_spec, syn_spec)

# ! Cortico-cortical, cross-orientation
print("Connecting: cortico-cortical, other orientation")
for source, target, conn_spec, syn_spec in ccxConnections:
    for src_i in range(name_dict[source]):
        for tgt_i in range(name_dict[target]):
            source_name = '{}_{}'.format(source, src_i)
            target_name = '{}_{}'.format(target, tgt_i)
            nest.Connect(Vp_h_layers[source_name], Vp_v_layers[target_name], conn_spec, syn_spec)
            nest.Connect(Vp_v_layers[source_name], Vp_h_layers[target_name], conn_spec, syn_spec)

# ! Cortico-thalamic connections
print("Connecting: cortico-thalamic")
for source, conn_spec, syn_spec in ctConnections:
    for src_i in range(name_dict[source]):
        source_name = '{}_{}'.format(source, src_i)
        nest.Connect(Vp_h_layers[source_name], TpRelay, conn_spec, syn_spec)
        nest.Connect(Vp_h_layers[source_name], TpInter, conn_spec, syn_spec)
        nest.Connect(Vp_v_layers[source_name], TpRelay, conn_spec, syn_spec)
        nest.Connect(Vp_v_layers[source_name], TpInter, conn_spec, syn_spec)

for src_i in range(name_dict['L56pyr']):
    source_name = 'L56pyr_{}'.format(src_i)
    nest.Connect(Vp_h_layers[source_name], Rp, corRet, corRet_syn_spec)
    nest.Connect(Vp_v_layers[source_name], Rp, corRet, corRet_syn_spec)

# ! Thalamo-cortical connections
# ! ----------------------------

# ! **Note:** According to the text on p. 1674, bottom right, of the Hill &
# ! Tononi paper, thalamocortical connections are created by selecting from
# ! the thalamic population for each L4 pyramidal cell. We must therefore
# ! specify that we want to select from the source neurons.
# !
# ! We first handle the rectangular thalamocortical connections.
thalCorRect_conn_spec = {"rule": "pairwise_bernoulli",
                         "use_on_source": True}

thalCorRect_syn_spec = {"synapse_model": "AMPA",
                        "weight": 5.0,
                        "delay": nest.random.uniform(min=2.75, max=3.25)}

print("Connecting: thalamo-cortical")

# ! Horizontally tuned
thalCorRect_conn_spec.update(
    {"mask": {"rectangular": {"lower_left": [-4.0 * dpc, -1.0 * dpc],
                              "upper_right": [4.0 * dpc, 1.0 * dpc]}}})

for conn in [{"targets": "L4pyr", "conn_spec": {"p": 0.5}},
             {"targets": "L56pyr", "conn_spec": {"p": 0.3}}]:
    conn_spec = thalCorRect_conn_spec.copy()
    conn_spec.update(conn['conn_spec'])
    for trg_i in range(name_dict[conn['targets']]):
        target_name = '{}_{}'.format(conn['targets'], trg_i)
        nest.Connect(
            TpRelay, Vp_h_layers[target_name], conn_spec, thalCorRect_syn_spec)

# ! Vertically tuned
thalCorRect_conn_spec.update(
    {"mask": {"rectangular": {"lower_left": [-1.0 * dpc, -4.0 * dpc],
                              "upper_right": [1.0 * dpc, 4.0 * dpc]}}})

for conn in [{"targets": "L4pyr", "conn_spec": {"p": 0.5}},
             {"targets": "L56pyr", "conn_spec": {"p": 0.3}}]:
    conn_spec = thalCorRect_conn_spec.copy()
    conn_spec.update(conn['conn_spec'])
    for trg_i in range(name_dict[conn['targets']]):
        target_name = '{}_{}'.format(conn['targets'], trg_i)
        nest.Connect(
            TpRelay, Vp_v_layers[target_name], conn_spec, thalCorRect_syn_spec)

# ! Diffuse connections
thalCorDiff_conn_spec = {"rule": "pairwise_bernoulli",
                         "use_on_source": True,
                         "mask": {"circular": {"radius": 5.0 * dpc}},
                         "p": 0.1*nest.spatial_distributions.gaussian(nest.spatial.distance, std=7.5*dpc)}

thalCorDiff_syn_spec = {"synapse_model": "AMPA",
                        "weight": 5.0,
                        "delay": nest.random.uniform(min=2.75, max=3.25)}

for conn in [{"targets": "L4pyr"},
             {"targets": "L56pyr"}]:
    for trg_i in range(name_dict[conn['targets']]):
        target_name = '{}_{}'.format(conn['targets'], trg_i)
        nest.Connect(TpRelay, Vp_h_layers[target_name], thalCorDiff_conn_spec, thalCorDiff_syn_spec)
        nest.Connect(TpRelay, Vp_v_layers[target_name], thalCorDiff_conn_spec, thalCorDiff_syn_spec)

# ! Thalamic connections
# ! --------------------

# ! Connections inside thalamus, including Rp.
# !
# ! *Note:* In Hill & Tononi, the inhibition between Rp cells is mediated by
# ! GABA_B receptors. We use GABA_A receptors here to provide some
# ! self-dampening of Rp.
# !
# ! **Note 1:** The following code had a serious bug in v. 0.1: During the first
# ! iteration of the loop, "synapse_model" and "weights" were set to "AMPA" and
# ! "0.1", respectively and remained unchanged, so that all connections were
# ! created as excitatory connections, even though they should have been
# ! inhibitory. We now specify synapse_model and weight explicitly for each
# ! connection to avoid this.
# !
# ! **Note 2:** The following code also had a serious bug in v. 0.4: In the
# ! loop the connection dictionary would be updated directly, i.e. without
# ! making a copy. This lead to the entry ``'sources': 'TpInter'`` being
# ! left in the dictionary when connecting with ``Rp`` sources. Therefore no
# ! connections for the connections with ``Rp`` as source would be created
# ! here.

thal_conn_spec = {"rule": "pairwise_bernoulli"}
thal_syn_spec = {"delay": nest.random.uniform(min=1.75, max=2.25)}

print("Connecting: intra-thalamic")

for src, tgt, conn, syn in [(TpRelay, Rp,
                             {"mask": {"circular": {"radius": 2.0 * dpc}},
                              "p": nest.spatial_distributions.gaussian(
                                 nest.spatial.distance, std=7.5*dpc)},
                             {"synapse_model": "AMPA",
                              "weight": 2.0}),
                            (TpInter, TpRelay,
                             {"mask": {"circular": {"radius": 2.0 * dpc}},
                              "p": 0.25*nest.spatial_distributions.gaussian(
                                 nest.spatial.distance, std=7.5*dpc)},
                             {"synapse_model": "GABA_A",
                              "weight": -1.0}),
                            (TpInter, TpInter,
                             {"mask": {"circular": {"radius": 2.0 * dpc}},
                              "p": 0.25*nest.spatial_distributions.gaussian(
                                 nest.spatial.distance, std=7.5*dpc)},
                             {"synapse_model": "GABA_A", "weight": -1.0}),
                            (Rp, TpRelay, {"mask": {"circular": {"radius": 12.0 * dpc}},
                                           "p": 0.15*nest.spatial_distributions.gaussian(
                                               nest.spatial.distance, std=7.5*dpc)},
                             {"synapse_model": "GABA_A", "weight": -1.0}),
                            (Rp, TpInter, {"mask": {"circular": {"radius": 12.0 * dpc}},
                                           "p": 0.15*nest.spatial_distributions.gaussian(
                                               nest.spatial.distance, std=7.5*dpc)},
                             {"synapse_model": "GABA_A", "weight": -1.0}),
                            (Rp, Rp, {"mask": {"circular": {"radius": 12.0 * dpc}},
                                      "p": 0.5*nest.spatial_distributions.gaussian(
                                          nest.spatial.distance, std=7.5*dpc)},
                             {"synapse_model": "GABA_A", "weight": -1.0})
                            ]:
    conn_spec = thal_conn_spec.copy()
    conn_spec.update(conn)
    syn_spec = thal_syn_spec.copy()
    syn_spec.update(syn)
    nest.Connect(src, tgt, conn_spec, syn_spec)


# ! Thalamic input
# ! --------------

# ! Input to the thalamus from the retina.
# !
# ! **Note:** Hill & Tononi specify a delay of 0 ms for this connection.
# ! We use 1 ms here.
retThal_conn_spec = {"rule": "pairwise_bernoulli",
                     "mask": {"circular": {"radius": 1.0 * dpc}},
                     "p": 0.75*nest.spatial_distributions.gaussian(nest.spatial.distance, std=2.5*dpc)}

retThal_syn_spec = {"weight": 10.0,
                    "delay": 1.0,
                    "synapse_model": "AMPA"}

print("Connecting: retino-thalamic")

nest.Connect(retina, TpRelay, retThal_conn_spec, retThal_syn_spec)
nest.Connect(retina, TpInter, retThal_conn_spec, retThal_syn_spec)

# ! Checks on connections
# ! ---------------------

# ! As a very simple check on the connections created, we inspect
# ! the connections from the central node of various layers.

# ! Connections from Retina to TpRelay
retina_ctr_gid = nest.FindCenterElement(retina)
retina_ctr_index = retina.index(retina_ctr_gid.get('global_id'))
conns = nest.GetConnections(retina[retina_ctr_index], TpRelay)
nest.PlotTargets(retina[retina_ctr_index], TpRelay, 'AMPA')
plt.title('Connections Retina -> TpRelay')

# ! Connections from TpRelay to L4pyr in Vp (horizontally tuned)
TpRelay_ctr_gid = nest.FindCenterElement(TpRelay)
TpRelay_ctr_index = TpRelay.index(TpRelay_ctr_gid.get('global_id'))
nest.PlotTargets(TpRelay[TpRelay_ctr_index], Vp_h_layers['L4pyr_0'], 'AMPA')
plt.title('Connections TpRelay -> Vp(h) L4pyr')

# ! Connections from TpRelay to L4pyr in Vp (vertically tuned)
nest.PlotTargets(TpRelay[TpRelay_ctr_index], Vp_v_layers['L4pyr_0'], 'AMPA')
plt.title('Connections TpRelay -> Vp(v) L4pyr')

# ! Block until the figures are closed before we continue.
plt.show(block=True)

# ! Recording devices
# ! =================

# ! This recording device setup is a bit makeshift. For each population
# ! we want to record from, we create one ``multimeter``, then select
# ! all nodes of the right model from the target population and
# ! connect. ``loc`` is the subplot location for the layer.
print("Connecting: Recording devices")
recorders = {}

for name, loc, population in [('TpRelay', 0, TpRelay),
                              ('Rp', 1, Rp),
                              ('Vp_v L4pyr 1', 2, Vp_v_layers['L4pyr_0']),
                              ('Vp_v L4pyr 2', 3, Vp_v_layers['L4pyr_1']),
                              ('Vp_h L4pyr 1', 4, Vp_h_layers['L4pyr_0']),
                              ('Vp_h L4pyr 2', 5, Vp_h_layers['L4pyr_1'])]:
    recorders[name] = (nest.Create('RecordingNode'), loc)
    # one recorder to all targets
    nest.Connect(recorders[name][0], population)

# ! Example simulation
# ! ====================

# ! This simulation is set up to create a step-wise visualization of
# ! the membrane potential. To do so, we simulate ``sim_interval``
# ! milliseconds at a time, then read out data from the multimeters,
# ! clear data from the multimeters and plot the data as pseudocolor
# ! plots.

# ! show time during simulation
nest.SetKernelStatus({'print_time': True})

# ! lower and upper limits for color scale, for each of the
# ! populations recorded.
vmn = [-80, -80, -80, -80, -80, -80]
vmx = [-50, -50, -50, -50, -50, -50]

# ! Because we are running the simulation in steps, we use the
# ! Prepare-Run-Cleanup procedure.
nest.Prepare()
nest.Run(Params['sim_interval'])

# ! Set up the figure, assume six recorders.
fig, axes = plt.subplots(2, 3)
images = []

for i, ax in enumerate(axes.flat):
    # We initialize with an empty image
    images.append(ax.imshow([[0.]], aspect='equal', interpolation='nearest',
                            extent=(0, Params['N'] + 1, 0, Params['N'] + 1),
                            vmin=vmn[i], vmax=vmx[i], cmap='plasma'))
    fig.colorbar(images[-1], ax=ax)

# ! loop over simulation intervals
for t in np.arange(0, Params['simtime'], Params['sim_interval']):

    # do the simulation
    nest.Run(Params['sim_interval'])

    # now plot data from each recorder in turn
    for name, rec_item in recorders.items():
        recorder, subplot_pos = rec_item
        ax = axes.flat[subplot_pos]
        im = images[subplot_pos]

        d = recorder.get('events', 'V_m')
        # clear data from multimeter
        recorder.set(n_events=0)

        # update image data and title
        im.set_data(np.reshape(d, (Params['N'], Params['N'])))
        ax.set_title(name + ', t = %6.1f ms' % nest.GetKernelStatus()['time'])

    # We need to pause because drawing of the figure happens while the main code is sleeping
    plt.pause(0.0001)

# ! Cleanup after the simulation is complete.
nest.Cleanup()

# ! just for some information at the end
pprint(nest.GetKernelStatus())
